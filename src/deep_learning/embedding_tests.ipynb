{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"../../data/mturk_experiment_2.csv\",encoding='unicode_escape')\n",
    "labels = data[\"Formality\"]\n",
    "samples = data[\"Sentence\"]\n",
    "\n",
    "train_samples, test_samples, train_labels,test_labels = train_test_split(samples, labels, test_size=0.2)\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "test_samples = np.array(test_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectoriser.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectoriser.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(glove_path,encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs,\"f\",sep= \" \")\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens,embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_tokens,embedding_dim,embeddings_initializer=keras.initializers.Constant(embedding_matrix),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 100)         1377900   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         12928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,440,493\n",
      "Trainable params: 62,593\n",
      "Non-trainable params: 1,377,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(1)(x)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(1)(x)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(units=1)(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectoriser(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectoriser(np.array([[s] for s in test_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error',metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.losses.MeanAbsoluteError(),tf.keras.losses.MeanAbsolutePercentageError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.3039 - mean_squared_error: 0.3039 - mean_absolute_error: 0.4336 - mean_absolute_percentage_error: 11.2081\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 8s 44ms/step - loss: 0.2891 - mean_squared_error: 0.2891 - mean_absolute_error: 0.4231 - mean_absolute_percentage_error: 10.9226\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 9s 52ms/step - loss: 0.2897 - mean_squared_error: 0.2897 - mean_absolute_error: 0.4218 - mean_absolute_percentage_error: 10.8976\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 9s 49ms/step - loss: 0.3001 - mean_squared_error: 0.3001 - mean_absolute_error: 0.4249 - mean_absolute_percentage_error: 10.9164\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 8s 43ms/step - loss: 0.2970 - mean_squared_error: 0.2970 - mean_absolute_error: 0.4295 - mean_absolute_percentage_error: 11.0300\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.3028 - mean_squared_error: 0.3028 - mean_absolute_error: 0.4313 - mean_absolute_percentage_error: 11.1381\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2811 - mean_squared_error: 0.2811 - mean_absolute_error: 0.4176 - mean_absolute_percentage_error: 10.8016\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 8s 43ms/step - loss: 0.2930 - mean_squared_error: 0.2930 - mean_absolute_error: 0.4263 - mean_absolute_percentage_error: 10.9233\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 7s 38ms/step - loss: 0.2884 - mean_squared_error: 0.2884 - mean_absolute_error: 0.4211 - mean_absolute_percentage_error: 10.8841\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 8s 43ms/step - loss: 0.2807 - mean_squared_error: 0.2807 - mean_absolute_error: 0.4159 - mean_absolute_percentage_error: 10.7342\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2838 - mean_squared_error: 0.2838 - mean_absolute_error: 0.4174 - mean_absolute_percentage_error: 10.7408\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 7s 38ms/step - loss: 0.2852 - mean_squared_error: 0.2852 - mean_absolute_error: 0.4145 - mean_absolute_percentage_error: 10.5582\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2856 - mean_squared_error: 0.2856 - mean_absolute_error: 0.4175 - mean_absolute_percentage_error: 10.7087\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2874 - mean_squared_error: 0.2874 - mean_absolute_error: 0.4184 - mean_absolute_percentage_error: 10.6582\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2799 - mean_squared_error: 0.2799 - mean_absolute_error: 0.4150 - mean_absolute_percentage_error: 10.6316\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2794 - mean_squared_error: 0.2794 - mean_absolute_error: 0.4125 - mean_absolute_percentage_error: 10.6129\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 7s 38ms/step - loss: 0.2666 - mean_squared_error: 0.2666 - mean_absolute_error: 0.4036 - mean_absolute_percentage_error: 10.3515\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 8s 44ms/step - loss: 0.2667 - mean_squared_error: 0.2667 - mean_absolute_error: 0.4014 - mean_absolute_percentage_error: 10.2905\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2737 - mean_squared_error: 0.2737 - mean_absolute_error: 0.4097 - mean_absolute_percentage_error: 10.4937\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2700 - mean_squared_error: 0.2700 - mean_absolute_error: 0.4061 - mean_absolute_percentage_error: 10.3973\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2585 - mean_squared_error: 0.2585 - mean_absolute_error: 0.3969 - mean_absolute_percentage_error: 10.2084\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2715 - mean_squared_error: 0.2715 - mean_absolute_error: 0.4037 - mean_absolute_percentage_error: 10.2999\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2598 - mean_squared_error: 0.2598 - mean_absolute_error: 0.4010 - mean_absolute_percentage_error: 10.3036\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2660 - mean_squared_error: 0.2660 - mean_absolute_error: 0.4014 - mean_absolute_percentage_error: 10.2935\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 7s 42ms/step - loss: 0.2553 - mean_squared_error: 0.2553 - mean_absolute_error: 0.3931 - mean_absolute_percentage_error: 10.0674\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 7s 41ms/step - loss: 0.2489 - mean_squared_error: 0.2489 - mean_absolute_error: 0.3902 - mean_absolute_percentage_error: 10.0304\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2604 - mean_squared_error: 0.2604 - mean_absolute_error: 0.4025 - mean_absolute_percentage_error: 10.2838\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2600 - mean_squared_error: 0.2600 - mean_absolute_error: 0.3995 - mean_absolute_percentage_error: 10.2059\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 7s 41ms/step - loss: 0.2554 - mean_squared_error: 0.2554 - mean_absolute_error: 0.3942 - mean_absolute_percentage_error: 10.0486\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2578 - mean_squared_error: 0.2578 - mean_absolute_error: 0.3943 - mean_absolute_percentage_error: 10.0540\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2550 - mean_squared_error: 0.2550 - mean_absolute_error: 0.3916 - mean_absolute_percentage_error: 10.0076\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2463 - mean_squared_error: 0.2463 - mean_absolute_error: 0.3878 - mean_absolute_percentage_error: 9.8713\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 7s 41ms/step - loss: 0.2468 - mean_squared_error: 0.2468 - mean_absolute_error: 0.3869 - mean_absolute_percentage_error: 9.8410\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 7s 38ms/step - loss: 0.2421 - mean_squared_error: 0.2421 - mean_absolute_error: 0.3833 - mean_absolute_percentage_error: 9.7788\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 7s 38ms/step - loss: 0.2447 - mean_squared_error: 0.2447 - mean_absolute_error: 0.3819 - mean_absolute_percentage_error: 9.6896\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 7s 38ms/step - loss: 0.2406 - mean_squared_error: 0.2406 - mean_absolute_error: 0.3853 - mean_absolute_percentage_error: 9.8033\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 7s 38ms/step - loss: 0.2383 - mean_squared_error: 0.2383 - mean_absolute_error: 0.3809 - mean_absolute_percentage_error: 9.6683\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 7s 38ms/step - loss: 0.2423 - mean_squared_error: 0.2423 - mean_absolute_error: 0.3839 - mean_absolute_percentage_error: 9.7796\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2428 - mean_squared_error: 0.2428 - mean_absolute_error: 0.3822 - mean_absolute_percentage_error: 9.6993\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2442 - mean_squared_error: 0.2442 - mean_absolute_error: 0.3865 - mean_absolute_percentage_error: 9.8102\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2410 - mean_squared_error: 0.2410 - mean_absolute_error: 0.3805 - mean_absolute_percentage_error: 9.6694\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2333 - mean_squared_error: 0.2333 - mean_absolute_error: 0.3755 - mean_absolute_percentage_error: 9.4727\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2396 - mean_squared_error: 0.2396 - mean_absolute_error: 0.3801 - mean_absolute_percentage_error: 9.6205\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2333 - mean_squared_error: 0.2333 - mean_absolute_error: 0.3734 - mean_absolute_percentage_error: 9.4916\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2337 - mean_squared_error: 0.2337 - mean_absolute_error: 0.3753 - mean_absolute_percentage_error: 9.5426\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2368 - mean_squared_error: 0.2368 - mean_absolute_error: 0.3803 - mean_absolute_percentage_error: 9.6397\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2329 - mean_squared_error: 0.2329 - mean_absolute_error: 0.3767 - mean_absolute_percentage_error: 9.5550\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2228 - mean_squared_error: 0.2228 - mean_absolute_error: 0.3669 - mean_absolute_percentage_error: 9.3323\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2335 - mean_squared_error: 0.2335 - mean_absolute_error: 0.3745 - mean_absolute_percentage_error: 9.4566\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 7s 40ms/step - loss: 0.2300 - mean_squared_error: 0.2300 - mean_absolute_error: 0.3713 - mean_absolute_percentage_error: 9.3794\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 7s 39ms/step - loss: 0.2354 - mean_squared_error: 0.2354 - mean_absolute_error: 0.3757 - mean_absolute_percentage_error: 9.5045\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.2235 - mean_squared_error: 0.2235 - mean_absolute_error: 0.3683 - mean_absolute_percentage_error: 9.3189\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 9s 49ms/step - loss: 0.2266 - mean_squared_error: 0.2266 - mean_absolute_error: 0.3709 - mean_absolute_percentage_error: 9.3565\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 9s 48ms/step - loss: 0.2269 - mean_squared_error: 0.2269 - mean_absolute_error: 0.3698 - mean_absolute_percentage_error: 9.3491\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2220 - mean_squared_error: 0.2220 - mean_absolute_error: 0.3687 - mean_absolute_percentage_error: 9.3032\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2187 - mean_squared_error: 0.2187 - mean_absolute_error: 0.3643 - mean_absolute_percentage_error: 9.2302\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.2313 - mean_squared_error: 0.2313 - mean_absolute_error: 0.3725 - mean_absolute_percentage_error: 9.3720\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2225 - mean_squared_error: 0.2225 - mean_absolute_error: 0.3639 - mean_absolute_percentage_error: 9.1963\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 8s 48ms/step - loss: 0.2212 - mean_squared_error: 0.2212 - mean_absolute_error: 0.3664 - mean_absolute_percentage_error: 9.2321\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 9s 49ms/step - loss: 0.2204 - mean_squared_error: 0.2204 - mean_absolute_error: 0.3650 - mean_absolute_percentage_error: 9.2019\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2237 - mean_squared_error: 0.2237 - mean_absolute_error: 0.3670 - mean_absolute_percentage_error: 9.2524\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2182 - mean_squared_error: 0.2182 - mean_absolute_error: 0.3597 - mean_absolute_percentage_error: 9.0343\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 9s 50ms/step - loss: 0.2200 - mean_squared_error: 0.2200 - mean_absolute_error: 0.3633 - mean_absolute_percentage_error: 9.1275\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2143 - mean_squared_error: 0.2143 - mean_absolute_error: 0.3583 - mean_absolute_percentage_error: 9.0036\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2151 - mean_squared_error: 0.2151 - mean_absolute_error: 0.3574 - mean_absolute_percentage_error: 9.0008\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2159 - mean_squared_error: 0.2159 - mean_absolute_error: 0.3587 - mean_absolute_percentage_error: 9.0126\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2133 - mean_squared_error: 0.2133 - mean_absolute_error: 0.3561 - mean_absolute_percentage_error: 8.9096\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.2115 - mean_squared_error: 0.2115 - mean_absolute_error: 0.3548 - mean_absolute_percentage_error: 8.9456\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.2110 - mean_squared_error: 0.2110 - mean_absolute_error: 0.3572 - mean_absolute_percentage_error: 8.9778\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2029 - mean_squared_error: 0.2029 - mean_absolute_error: 0.3483 - mean_absolute_percentage_error: 8.7746\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 8s 48ms/step - loss: 0.2044 - mean_squared_error: 0.2044 - mean_absolute_error: 0.3499 - mean_absolute_percentage_error: 8.8412\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 10s 60ms/step - loss: 0.2014 - mean_squared_error: 0.2014 - mean_absolute_error: 0.3488 - mean_absolute_percentage_error: 8.7710\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 10s 56ms/step - loss: 0.1958 - mean_squared_error: 0.1958 - mean_absolute_error: 0.3428 - mean_absolute_percentage_error: 8.6617\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.1984 - mean_squared_error: 0.1984 - mean_absolute_error: 0.3430 - mean_absolute_percentage_error: 8.6213\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 9s 51ms/step - loss: 0.1935 - mean_squared_error: 0.1935 - mean_absolute_error: 0.3415 - mean_absolute_percentage_error: 8.6435\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 9s 50ms/step - loss: 0.1989 - mean_squared_error: 0.1989 - mean_absolute_error: 0.3446 - mean_absolute_percentage_error: 8.6132\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.2038 - mean_squared_error: 0.2038 - mean_absolute_error: 0.3475 - mean_absolute_percentage_error: 8.7303\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 8s 48ms/step - loss: 0.2052 - mean_squared_error: 0.2052 - mean_absolute_error: 0.3482 - mean_absolute_percentage_error: 8.7084\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 9s 50ms/step - loss: 0.2006 - mean_squared_error: 0.2006 - mean_absolute_error: 0.3482 - mean_absolute_percentage_error: 8.7555\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.1999 - mean_squared_error: 0.1999 - mean_absolute_error: 0.3489 - mean_absolute_percentage_error: 8.7928\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 9s 49ms/step - loss: 0.1979 - mean_squared_error: 0.1979 - mean_absolute_error: 0.3428 - mean_absolute_percentage_error: 8.6384\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 9s 51ms/step - loss: 0.2003 - mean_squared_error: 0.2003 - mean_absolute_error: 0.3460 - mean_absolute_percentage_error: 8.6821\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 8s 48ms/step - loss: 0.1959 - mean_squared_error: 0.1959 - mean_absolute_error: 0.3408 - mean_absolute_percentage_error: 8.5502\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.1862 - mean_squared_error: 0.1862 - mean_absolute_error: 0.3307 - mean_absolute_percentage_error: 8.2759\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 9s 53ms/step - loss: 0.1868 - mean_squared_error: 0.1868 - mean_absolute_error: 0.3336 - mean_absolute_percentage_error: 8.4074\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 9s 51ms/step - loss: 0.1916 - mean_squared_error: 0.1916 - mean_absolute_error: 0.3362 - mean_absolute_percentage_error: 8.4193\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.1879 - mean_squared_error: 0.1879 - mean_absolute_error: 0.3331 - mean_absolute_percentage_error: 8.3496\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 9s 49ms/step - loss: 0.1964 - mean_squared_error: 0.1964 - mean_absolute_error: 0.3421 - mean_absolute_percentage_error: 8.5828\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 8s 45ms/step - loss: 0.1879 - mean_squared_error: 0.1879 - mean_absolute_error: 0.3329 - mean_absolute_percentage_error: 8.3742\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 8s 44ms/step - loss: 0.1948 - mean_squared_error: 0.1948 - mean_absolute_error: 0.3378 - mean_absolute_percentage_error: 8.4290\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 8s 48ms/step - loss: 0.2039 - mean_squared_error: 0.2039 - mean_absolute_error: 0.3461 - mean_absolute_percentage_error: 8.6632\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.1904 - mean_squared_error: 0.1904 - mean_absolute_error: 0.3343 - mean_absolute_percentage_error: 8.3449\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.1856 - mean_squared_error: 0.1856 - mean_absolute_error: 0.3314 - mean_absolute_percentage_error: 8.2831\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 8s 45ms/step - loss: 0.1884 - mean_squared_error: 0.1884 - mean_absolute_error: 0.3351 - mean_absolute_percentage_error: 8.3677\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.1868 - mean_squared_error: 0.1868 - mean_absolute_error: 0.3348 - mean_absolute_percentage_error: 8.3680\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 8s 48ms/step - loss: 0.1859 - mean_squared_error: 0.1859 - mean_absolute_error: 0.3325 - mean_absolute_percentage_error: 8.3385\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 8s 47ms/step - loss: 0.1828 - mean_squared_error: 0.1828 - mean_absolute_error: 0.3283 - mean_absolute_percentage_error: 8.1457\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.1822 - mean_squared_error: 0.1822 - mean_absolute_error: 0.3298 - mean_absolute_percentage_error: 8.2222\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.1813 - mean_squared_error: 0.1813 - mean_absolute_error: 0.3277 - mean_absolute_percentage_error: 8.1675\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 8s 46ms/step - loss: 0.1896 - mean_squared_error: 0.1896 - mean_absolute_error: 0.3354 - mean_absolute_percentage_error: 8.3992\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,y=y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>% Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303857</td>\n",
       "      <td>0.433553</td>\n",
       "      <td>11.208060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289113</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>10.922573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.289703</td>\n",
       "      <td>0.421789</td>\n",
       "      <td>10.897609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300052</td>\n",
       "      <td>0.424854</td>\n",
       "      <td>10.916362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.297047</td>\n",
       "      <td>0.429541</td>\n",
       "      <td>11.029952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.185888</td>\n",
       "      <td>0.332464</td>\n",
       "      <td>8.338457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.182806</td>\n",
       "      <td>0.328343</td>\n",
       "      <td>8.145698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.182230</td>\n",
       "      <td>0.329782</td>\n",
       "      <td>8.222215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.181338</td>\n",
       "      <td>0.327712</td>\n",
       "      <td>8.167513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.189641</td>\n",
       "      <td>0.335446</td>\n",
       "      <td>8.399154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE       MAE    % Error\n",
       "0   0.303857  0.433553  11.208060\n",
       "1   0.289113  0.423077  10.922573\n",
       "2   0.289703  0.421789  10.897609\n",
       "3   0.300052  0.424854  10.916362\n",
       "4   0.297047  0.429541  11.029952\n",
       "..       ...       ...        ...\n",
       "95  0.185888  0.332464   8.338457\n",
       "96  0.182806  0.328343   8.145698\n",
       "97  0.182230  0.329782   8.222215\n",
       "98  0.181338  0.327712   8.167513\n",
       "99  0.189641  0.335446   8.399154\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = history.history['mean_squared_error']\n",
    "mae = history.history['mean_absolute_error']\n",
    "mpe = history.history['mean_absolute_percentage_error']\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "scores[\"MSE\"] = mse\n",
    "scores[\"MAE\"] = mae\n",
    "scores[\"% Error\"] = mpe\n",
    "\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2292f7dadeec0b36dafabb7d1d8dd7b9b8b8f0665c515bec64e67bf9650aaf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
