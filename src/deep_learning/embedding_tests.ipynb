{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"../../data/mturk_experiment_2.csv\",encoding='unicode_escape')\n",
    "labels = data[\"Formality\"]\n",
    "samples = data[\"Sentence\"]\n",
    "\n",
    "train_samples, test_samples, train_labels,test_labels = train_test_split(samples, labels, test_size=0.2)\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "test_samples = np.array(test_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectoriser.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectoriser.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(glove_path,encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs,\"f\",sep= \" \")\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens,embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_tokens,embedding_dim,embeddings_initializer=keras.initializers.Constant(embedding_matrix),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, 100)         1377700   \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, None, 128)         12928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,440,293\n",
      "Trainable params: 62,593\n",
      "Non-trainable params: 1,377,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(1)(x)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(1)(x)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(units=1)(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectoriser(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectoriser(np.array([[s] for s in test_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.01),loss='mean_squared_error',metrics=[tf.keras.metrics.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 9s 7ms/step - loss: 1.4528 - mean_squared_error: 1.4528\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0384 - mean_squared_error: 1.0384\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 8s 8ms/step - loss: 0.9224 - mean_squared_error: 0.9224\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0351 - mean_squared_error: 1.0351\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0695 - mean_squared_error: 1.0695\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0640 - mean_squared_error: 1.0640\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0875 - mean_squared_error: 1.0875\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0059 - mean_squared_error: 1.0059\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0187 - mean_squared_error: 1.0187\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0213 - mean_squared_error: 1.0213\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0448 - mean_squared_error: 1.0448\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 8s 8ms/step - loss: 1.0507 - mean_squared_error: 1.0507\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0500 - mean_squared_error: 1.0500\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0474 - mean_squared_error: 1.0474\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 9s 8ms/step - loss: 1.0551 - mean_squared_error: 1.0551\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0375 - mean_squared_error: 1.0375\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0502 - mean_squared_error: 1.0502\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0422 - mean_squared_error: 1.0422\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 8s 7ms/step - loss: 1.0490 - mean_squared_error: 1.0490\n",
      "Epoch 20/100\n",
      " 703/1125 [=================>............] - ETA: 3s - loss: 1.0171 - mean_squared_error: 1.0171"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,y=y_train,batch_size=5,epochs=100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2292f7dadeec0b36dafabb7d1d8dd7b9b8b8f0665c515bec64e67bf9650aaf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
