{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"../../data/mturk_experiment_2.csv\",encoding='unicode_escape')\n",
    "labels = data[\"Formality\"]\n",
    "samples = data[\"Sentence\"]\n",
    "\n",
    "train_samples, test_samples, train_labels,test_labels = train_test_split(samples, labels, test_size=0.2)\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "test_samples = np.array(test_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectoriser.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectoriser.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(glove_path,encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs,\"f\",sep= \" \")\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens,embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_tokens,embedding_dim,embeddings_initializer=keras.initializers.Constant(embedding_matrix),trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 100)         1383900   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         12928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         16512     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,446,493\n",
      "Trainable params: 62,593\n",
      "Non-trainable params: 1,383,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(1)(x)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(1)(x)\n",
    "x = layers.Conv1D(128, 1, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(units=1)(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectoriser(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectoriser(np.array([[s] for s in test_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='mean_squared_error',metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.losses.MeanAbsoluteError(),tf.keras.losses.MeanAbsolutePercentageError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "176/176 [==============================] - 4s 19ms/step - loss: 3.4668 - mean_squared_error: 3.4668 - mean_absolute_error: 1.4414 - mean_absolute_percentage_error: 36.7682\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 4s 21ms/step - loss: 1.2474 - mean_squared_error: 1.2474 - mean_absolute_error: 0.8984 - mean_absolute_percentage_error: 24.6271\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 1.1131 - mean_squared_error: 1.1131 - mean_absolute_error: 0.8416 - mean_absolute_percentage_error: 22.9285\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 1.0360 - mean_squared_error: 1.0360 - mean_absolute_error: 0.8139 - mean_absolute_percentage_error: 22.1445\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.9997 - mean_squared_error: 0.9997 - mean_absolute_error: 0.7997 - mean_absolute_percentage_error: 21.6859\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.9283 - mean_squared_error: 0.9283 - mean_absolute_error: 0.7693 - mean_absolute_percentage_error: 20.9180\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.9245 - mean_squared_error: 0.9245 - mean_absolute_error: 0.7633 - mean_absolute_percentage_error: 20.7081\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 6s 34ms/step - loss: 0.8862 - mean_squared_error: 0.8862 - mean_absolute_error: 0.7548 - mean_absolute_percentage_error: 20.5564\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.8508 - mean_squared_error: 0.8508 - mean_absolute_error: 0.7384 - mean_absolute_percentage_error: 20.0321\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.8128 - mean_squared_error: 0.8128 - mean_absolute_error: 0.7235 - mean_absolute_percentage_error: 19.6699\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 6s 31ms/step - loss: 0.8434 - mean_squared_error: 0.8434 - mean_absolute_error: 0.7289 - mean_absolute_percentage_error: 19.7824\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.8285 - mean_squared_error: 0.8285 - mean_absolute_error: 0.7262 - mean_absolute_percentage_error: 19.6674\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.7828 - mean_squared_error: 0.7828 - mean_absolute_error: 0.7067 - mean_absolute_percentage_error: 19.1513\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.8195 - mean_squared_error: 0.8195 - mean_absolute_error: 0.7243 - mean_absolute_percentage_error: 19.6077\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.8026 - mean_squared_error: 0.8026 - mean_absolute_error: 0.7186 - mean_absolute_percentage_error: 19.4996\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.7611 - mean_squared_error: 0.7611 - mean_absolute_error: 0.6958 - mean_absolute_percentage_error: 18.7787\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.7587 - mean_squared_error: 0.7587 - mean_absolute_error: 0.6940 - mean_absolute_percentage_error: 18.8625\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.7476 - mean_squared_error: 0.7476 - mean_absolute_error: 0.6934 - mean_absolute_percentage_error: 18.6778\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 4s 23ms/step - loss: 0.7230 - mean_squared_error: 0.7230 - mean_absolute_error: 0.6764 - mean_absolute_percentage_error: 18.3736\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 4s 25ms/step - loss: 0.7218 - mean_squared_error: 0.7218 - mean_absolute_error: 0.6779 - mean_absolute_percentage_error: 18.2976\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.7210 - mean_squared_error: 0.7210 - mean_absolute_error: 0.6791 - mean_absolute_percentage_error: 18.2598\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 4s 25ms/step - loss: 0.7137 - mean_squared_error: 0.7137 - mean_absolute_error: 0.6763 - mean_absolute_percentage_error: 18.2640\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 4s 24ms/step - loss: 0.6890 - mean_squared_error: 0.6890 - mean_absolute_error: 0.6644 - mean_absolute_percentage_error: 17.9449\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 4s 24ms/step - loss: 0.6900 - mean_squared_error: 0.6900 - mean_absolute_error: 0.6652 - mean_absolute_percentage_error: 17.8579\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 4s 24ms/step - loss: 0.6630 - mean_squared_error: 0.6630 - mean_absolute_error: 0.6520 - mean_absolute_percentage_error: 17.6380\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 4s 24ms/step - loss: 0.6644 - mean_squared_error: 0.6644 - mean_absolute_error: 0.6515 - mean_absolute_percentage_error: 17.5153\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 4s 24ms/step - loss: 0.6483 - mean_squared_error: 0.6483 - mean_absolute_error: 0.6408 - mean_absolute_percentage_error: 17.2102\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 4s 24ms/step - loss: 0.6447 - mean_squared_error: 0.6447 - mean_absolute_error: 0.6385 - mean_absolute_percentage_error: 17.1204\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 4s 24ms/step - loss: 0.6389 - mean_squared_error: 0.6389 - mean_absolute_error: 0.6380 - mean_absolute_percentage_error: 17.1632\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.6232 - mean_squared_error: 0.6232 - mean_absolute_error: 0.6251 - mean_absolute_percentage_error: 16.7695\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.6047 - mean_squared_error: 0.6047 - mean_absolute_error: 0.6199 - mean_absolute_percentage_error: 16.6989\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.6042 - mean_squared_error: 0.6042 - mean_absolute_error: 0.6192 - mean_absolute_percentage_error: 16.6282\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.5924 - mean_squared_error: 0.5924 - mean_absolute_error: 0.6131 - mean_absolute_percentage_error: 16.4567\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.5934 - mean_squared_error: 0.5934 - mean_absolute_error: 0.6143 - mean_absolute_percentage_error: 16.5510\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.6134 - mean_squared_error: 0.6134 - mean_absolute_error: 0.6274 - mean_absolute_percentage_error: 16.8103\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.5755 - mean_squared_error: 0.5755 - mean_absolute_error: 0.6032 - mean_absolute_percentage_error: 16.1716\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.5566 - mean_squared_error: 0.5566 - mean_absolute_error: 0.5971 - mean_absolute_percentage_error: 15.9820\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.5410 - mean_squared_error: 0.5410 - mean_absolute_error: 0.5850 - mean_absolute_percentage_error: 15.6471\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.5410 - mean_squared_error: 0.5410 - mean_absolute_error: 0.5853 - mean_absolute_percentage_error: 15.7274\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.5500 - mean_squared_error: 0.5500 - mean_absolute_error: 0.5870 - mean_absolute_percentage_error: 15.6433\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 4s 25ms/step - loss: 0.5414 - mean_squared_error: 0.5414 - mean_absolute_error: 0.5838 - mean_absolute_percentage_error: 15.5698\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.5082 - mean_squared_error: 0.5082 - mean_absolute_error: 0.5698 - mean_absolute_percentage_error: 15.2396\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 4s 25ms/step - loss: 0.5134 - mean_squared_error: 0.5134 - mean_absolute_error: 0.5689 - mean_absolute_percentage_error: 15.1327\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.5073 - mean_squared_error: 0.5073 - mean_absolute_error: 0.5665 - mean_absolute_percentage_error: 15.1244\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.5087 - mean_squared_error: 0.5087 - mean_absolute_error: 0.5677 - mean_absolute_percentage_error: 15.0664\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.5100 - mean_squared_error: 0.5100 - mean_absolute_error: 0.5648 - mean_absolute_percentage_error: 15.0306\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.5057 - mean_squared_error: 0.5057 - mean_absolute_error: 0.5645 - mean_absolute_percentage_error: 14.9959\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.4659 - mean_squared_error: 0.4659 - mean_absolute_error: 0.5430 - mean_absolute_percentage_error: 14.4709\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.4776 - mean_squared_error: 0.4776 - mean_absolute_error: 0.5459 - mean_absolute_percentage_error: 14.5968\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.4704 - mean_squared_error: 0.4704 - mean_absolute_error: 0.5441 - mean_absolute_percentage_error: 14.4066\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.4718 - mean_squared_error: 0.4718 - mean_absolute_error: 0.5440 - mean_absolute_percentage_error: 14.3601\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 5s 26ms/step - loss: 0.4709 - mean_squared_error: 0.4709 - mean_absolute_error: 0.5411 - mean_absolute_percentage_error: 14.2907\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.4592 - mean_squared_error: 0.4592 - mean_absolute_error: 0.5376 - mean_absolute_percentage_error: 14.1894\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.4396 - mean_squared_error: 0.4396 - mean_absolute_error: 0.5261 - mean_absolute_percentage_error: 13.9451\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.4322 - mean_squared_error: 0.4322 - mean_absolute_error: 0.5221 - mean_absolute_percentage_error: 13.8458\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.4317 - mean_squared_error: 0.4317 - mean_absolute_error: 0.5228 - mean_absolute_percentage_error: 13.8074\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.4263 - mean_squared_error: 0.4263 - mean_absolute_error: 0.5175 - mean_absolute_percentage_error: 13.6903\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.4155 - mean_squared_error: 0.4155 - mean_absolute_error: 0.5141 - mean_absolute_percentage_error: 13.5558\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.4319 - mean_squared_error: 0.4319 - mean_absolute_error: 0.5203 - mean_absolute_percentage_error: 13.7332\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.4102 - mean_squared_error: 0.4102 - mean_absolute_error: 0.5075 - mean_absolute_percentage_error: 13.4542\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.4144 - mean_squared_error: 0.4144 - mean_absolute_error: 0.5080 - mean_absolute_percentage_error: 13.3522\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.4139 - mean_squared_error: 0.4139 - mean_absolute_error: 0.5093 - mean_absolute_percentage_error: 13.4536\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.4009 - mean_squared_error: 0.4009 - mean_absolute_error: 0.4989 - mean_absolute_percentage_error: 13.1066\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.3981 - mean_squared_error: 0.3981 - mean_absolute_error: 0.4999 - mean_absolute_percentage_error: 13.1913\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 6s 31ms/step - loss: 0.3796 - mean_squared_error: 0.3796 - mean_absolute_error: 0.4852 - mean_absolute_percentage_error: 12.7347\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 6s 32ms/step - loss: 0.3713 - mean_squared_error: 0.3713 - mean_absolute_error: 0.4798 - mean_absolute_percentage_error: 12.6249\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.3781 - mean_squared_error: 0.3781 - mean_absolute_error: 0.4855 - mean_absolute_percentage_error: 12.7158\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3776 - mean_squared_error: 0.3776 - mean_absolute_error: 0.4867 - mean_absolute_percentage_error: 12.7295\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 5s 31ms/step - loss: 0.3742 - mean_squared_error: 0.3742 - mean_absolute_error: 0.4836 - mean_absolute_percentage_error: 12.6281\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.3688 - mean_squared_error: 0.3688 - mean_absolute_error: 0.4802 - mean_absolute_percentage_error: 12.5830\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.3708 - mean_squared_error: 0.3708 - mean_absolute_error: 0.4771 - mean_absolute_percentage_error: 12.4348\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.3646 - mean_squared_error: 0.3646 - mean_absolute_error: 0.4806 - mean_absolute_percentage_error: 12.5658\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3625 - mean_squared_error: 0.3625 - mean_absolute_error: 0.4755 - mean_absolute_percentage_error: 12.3943\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3588 - mean_squared_error: 0.3588 - mean_absolute_error: 0.4707 - mean_absolute_percentage_error: 12.2219\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.3491 - mean_squared_error: 0.3491 - mean_absolute_error: 0.4654 - mean_absolute_percentage_error: 12.1739\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3558 - mean_squared_error: 0.3558 - mean_absolute_error: 0.4709 - mean_absolute_percentage_error: 12.1660\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3526 - mean_squared_error: 0.3526 - mean_absolute_error: 0.4690 - mean_absolute_percentage_error: 12.2029\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3405 - mean_squared_error: 0.3405 - mean_absolute_error: 0.4588 - mean_absolute_percentage_error: 11.9019\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3325 - mean_squared_error: 0.3325 - mean_absolute_error: 0.4565 - mean_absolute_percentage_error: 11.9082\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3397 - mean_squared_error: 0.3397 - mean_absolute_error: 0.4599 - mean_absolute_percentage_error: 11.9343\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3380 - mean_squared_error: 0.3380 - mean_absolute_error: 0.4593 - mean_absolute_percentage_error: 11.8888\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3289 - mean_squared_error: 0.3289 - mean_absolute_error: 0.4538 - mean_absolute_percentage_error: 11.7906\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3220 - mean_squared_error: 0.3220 - mean_absolute_error: 0.4467 - mean_absolute_percentage_error: 11.6011\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - mean_absolute_error: 0.4528 - mean_absolute_percentage_error: 11.7519\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.3234 - mean_squared_error: 0.3234 - mean_absolute_error: 0.4463 - mean_absolute_percentage_error: 11.5860\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3166 - mean_squared_error: 0.3166 - mean_absolute_error: 0.4422 - mean_absolute_percentage_error: 11.4567\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3298 - mean_squared_error: 0.3298 - mean_absolute_error: 0.4527 - mean_absolute_percentage_error: 11.6447\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3258 - mean_squared_error: 0.3258 - mean_absolute_error: 0.4503 - mean_absolute_percentage_error: 11.6292\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.2964 - mean_squared_error: 0.2964 - mean_absolute_error: 0.4267 - mean_absolute_percentage_error: 11.0337\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3186 - mean_squared_error: 0.3186 - mean_absolute_error: 0.4468 - mean_absolute_percentage_error: 11.5356\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 5s 30ms/step - loss: 0.3090 - mean_squared_error: 0.3090 - mean_absolute_error: 0.4353 - mean_absolute_percentage_error: 11.2703\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 5s 29ms/step - loss: 0.2943 - mean_squared_error: 0.2943 - mean_absolute_error: 0.4239 - mean_absolute_percentage_error: 10.9389\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.2991 - mean_squared_error: 0.2991 - mean_absolute_error: 0.4295 - mean_absolute_percentage_error: 11.1166\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.3016 - mean_squared_error: 0.3016 - mean_absolute_error: 0.4337 - mean_absolute_percentage_error: 11.1821\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.2970 - mean_squared_error: 0.2970 - mean_absolute_error: 0.4313 - mean_absolute_percentage_error: 11.1012\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3053 - mean_squared_error: 0.3053 - mean_absolute_error: 0.4329 - mean_absolute_percentage_error: 11.0901\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.2885 - mean_squared_error: 0.2885 - mean_absolute_error: 0.4210 - mean_absolute_percentage_error: 10.8657\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.2881 - mean_squared_error: 0.2881 - mean_absolute_error: 0.4231 - mean_absolute_percentage_error: 10.9790\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 5s 27ms/step - loss: 0.2947 - mean_squared_error: 0.2947 - mean_absolute_error: 0.4250 - mean_absolute_percentage_error: 10.8550\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 5s 28ms/step - loss: 0.3018 - mean_squared_error: 0.3018 - mean_absolute_error: 0.4341 - mean_absolute_percentage_error: 11.1359\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train,y=y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>% Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.466813</td>\n",
       "      <td>1.441424</td>\n",
       "      <td>36.768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.247407</td>\n",
       "      <td>0.898405</td>\n",
       "      <td>24.627058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.113067</td>\n",
       "      <td>0.841636</td>\n",
       "      <td>22.928469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.036033</td>\n",
       "      <td>0.813882</td>\n",
       "      <td>22.144453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.799659</td>\n",
       "      <td>21.685909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.305326</td>\n",
       "      <td>0.432868</td>\n",
       "      <td>11.090082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.288539</td>\n",
       "      <td>0.420973</td>\n",
       "      <td>10.865730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.288064</td>\n",
       "      <td>0.423097</td>\n",
       "      <td>10.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.294685</td>\n",
       "      <td>0.425035</td>\n",
       "      <td>10.854995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.301797</td>\n",
       "      <td>0.434068</td>\n",
       "      <td>11.135926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE       MAE    % Error\n",
       "0   3.466813  1.441424  36.768200\n",
       "1   1.247407  0.898405  24.627058\n",
       "2   1.113067  0.841636  22.928469\n",
       "3   1.036033  0.813882  22.144453\n",
       "4   0.999670  0.799659  21.685909\n",
       "..       ...       ...        ...\n",
       "95  0.305326  0.432868  11.090082\n",
       "96  0.288539  0.420973  10.865730\n",
       "97  0.288064  0.423097  10.979000\n",
       "98  0.294685  0.425035  10.854995\n",
       "99  0.301797  0.434068  11.135926\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = history.history['mean_squared_error']\n",
    "mae = history.history['mean_absolute_error']\n",
    "mpe = history.history['mean_absolute_percentage_error']\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "scores[\"MSE\"] = mse\n",
    "scores[\"MAE\"] = mae\n",
    "scores[\"% Error\"] = mpe\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 5ms/step - loss: 0.8018 - mean_squared_error: 0.8018 - mean_absolute_error: 0.7049 - mean_absolute_percentage_error: 19.4670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.801812469959259, 0.7049391269683838, 19.467012405395508]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x=x_val,y=y_val)\n",
    "scores[1:]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2292f7dadeec0b36dafabb7d1d8dd7b9b8b8f0665c515bec64e67bf9650aaf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
