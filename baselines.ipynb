{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(\"data/mturk_experiment_2.csv\",encoding='unicode_escape')\n",
    "feature_names = [\"Informativeness\",\"Implicature\",\"Length in Words\",\"Length in Characters\",\"F-score\",\"I-score\",\"Lexical Density\"]\n",
    "features = data[feature_names]\n",
    "target = data[\"Formality\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up K-Folds and scoring\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scoring = [\"r2\",\"neg_mean_squared_error\",\"neg_median_absolute_error\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00436211, 0.00307083, 0.00357127, 0.00300026, 0.0022049 ,\n",
       "        0.00279403, 0.00187635, 0.0030601 , 0.00259995, 0.00287938]),\n",
       " 'score_time': array([0.00100541, 0.00229907, 0.00099969, 0.00108814, 0.0015192 ,\n",
       "        0.00101209, 0.00200891, 0.00110126, 0.00100255, 0.00099564]),\n",
       " 'test_r2': array([0.56952603, 0.55882205, 0.60617977, 0.56048608, 0.51722343,\n",
       "        0.5980286 , 0.57403479, 0.57344594, 0.56994064, 0.5237644 ]),\n",
       " 'test_neg_mean_squared_error': array([-0.54095146, -0.57153626, -0.50594363, -0.54133643, -0.61174158,\n",
       "        -0.53110344, -0.53931864, -0.5373336 , -0.54752164, -0.56809796]),\n",
       " 'test_neg_median_absolute_error': array([-0.49650966, -0.50503012, -0.46680883, -0.51525232, -0.52758131,\n",
       "        -0.50007299, -0.50717377, -0.5307477 , -0.49320295, -0.49973068])}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg_scores = cross_validate(lin_reg, X_train, y_train, cv=cv,scoring=scoring)\n",
    "lin_reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00200772, 0.00200057, 0.00200033, 0.00299764, 0.00106478,\n",
       "        0.00192261, 0.00200653, 0.0022881 , 0.00235796, 0.00199938]),\n",
       " 'score_time': array([0.00198698, 0.00153852, 0.00101113, 0.00106192, 0.0010097 ,\n",
       "        0.00204444, 0.00099874, 0.00100565, 0.001019  , 0.00099969]),\n",
       " 'test_r2': array([0.56952546, 0.55882348, 0.60618161, 0.56049061, 0.51721175,\n",
       "        0.59803064, 0.57403306, 0.57344741, 0.56993484, 0.52377141]),\n",
       " 'test_neg_mean_squared_error': array([-0.54095217, -0.57153442, -0.50594127, -0.54133085, -0.61175638,\n",
       "        -0.53110074, -0.53932083, -0.53733175, -0.54752903, -0.56808961]),\n",
       " 'test_neg_median_absolute_error': array([-0.49638495, -0.50501619, -0.46664425, -0.51530712, -0.52755323,\n",
       "        -0.50000561, -0.50735819, -0.5306824 , -0.49333987, -0.49979055])}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge regression\n",
    "ridge_reg = linear_model.Ridge()\n",
    "ridge_reg_scores = cross_validate(ridge_reg, X_train, y_train, cv=cv,scoring=scoring)\n",
    "ridge_reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00483131, 0.00362515, 0.00399995, 0.00273776, 0.00307035,\n",
       "        0.00399637, 0.0026145 , 0.00325084, 0.00292039, 0.00337505]),\n",
       " 'score_time': array([0.00099969, 0.00254011, 0.00100088, 0.00221515, 0.00092936,\n",
       "        0.00099921, 0.00100183, 0.00208211, 0.00199366, 0.00100207]),\n",
       " 'test_r2': array([0.27301323, 0.3122612 , 0.37413842, 0.30872804, 0.16829899,\n",
       "        0.35658596, 0.30606951, 0.32101272, 0.29013334, 0.29119036]),\n",
       " 'test_neg_mean_squared_error': array([-0.91356174, -0.89095038, -0.80404881, -0.85141944, -1.05387485,\n",
       "        -0.85010875, -0.87859205, -0.85532576, -0.90375283, -0.84553384]),\n",
       " 'test_neg_median_absolute_error': array([-0.65066255, -0.69573015, -0.63155322, -0.66661358, -0.65491924,\n",
       "        -0.6756198 , -0.67895819, -0.67173617, -0.63259848, -0.66627669])}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso regression\n",
    "lasso_reg = linear_model.Lasso()\n",
    "lasso_reg_scores = cross_validate(lasso_reg, X_train, y_train, cv=cv,scoring=scoring)\n",
    "lasso_reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00298643, 0.00316978, 0.00205064, 0.00201941, 0.0030911 ,\n",
       "        0.00359106, 0.00193095, 0.00200129, 0.00199461, 0.00224924]),\n",
       " 'score_time': array([0.00300074, 0.00200343, 0.00103307, 0.00189567, 0.00090837,\n",
       "        0.00034356, 0.00099969, 0.00199938, 0.00253606, 0.00187898]),\n",
       " 'test_r2': array([0.27301312, 0.31226127, 0.37413918, 0.30872804, 0.16829878,\n",
       "        0.35658603, 0.30606955, 0.32101276, 0.29013331, 0.29119033]),\n",
       " 'test_neg_mean_squared_error': array([-0.91356189, -0.8909503 , -0.80404783, -0.85141944, -1.05387512,\n",
       "        -0.85010867, -0.878592  , -0.85532572, -0.90375287, -0.84553387]),\n",
       " 'test_neg_median_absolute_error': array([-0.65066312, -0.69572917, -0.63155849, -0.66661341, -0.65491856,\n",
       "        -0.67561988, -0.67895844, -0.67173572, -0.6325981 , -0.66627659])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LARS Lasso\n",
    "lars_lasso_reg = linear_model.LassoLars(normalize=False)\n",
    "lars_lasso_reg_scores = cross_validate(lars_lasso_reg, X_train, y_train, cv=cv,scoring=scoring)\n",
    "lars_lasso_reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00589132, 0.00464725, 0.0060792 , 0.00639939, 0.0063653 ,\n",
       "        0.00671554, 0.00513053, 0.00703144, 0.00634646, 0.00566816]),\n",
       " 'score_time': array([0.00366855, 0.00200081, 0.0011549 , 0.00100255, 0.00219035,\n",
       "        0.00109053, 0.00100255, 0.00099826, 0.00301266, 0.00107002]),\n",
       " 'test_r2': array([0.56951939, 0.55883407, 0.60619587, 0.56052689, 0.51711185,\n",
       "        0.59804647, 0.5740173 , 0.57345848, 0.56988434, 0.52382791]),\n",
       " 'test_neg_mean_squared_error': array([-0.5409598 , -0.57152069, -0.50592296, -0.54128617, -0.61188296,\n",
       "        -0.53107983, -0.53934079, -0.53731781, -0.54759333, -0.56802221]),\n",
       " 'test_neg_median_absolute_error': array([-0.49533888, -0.50490027, -0.46849362, -0.5157628 , -0.52731069,\n",
       "        -0.49944142, -0.50805326, -0.52946868, -0.49368968, -0.5002839 ])}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian Ridge Regression\n",
    "bayesian_ridge_reg = linear_model.BayesianRidge()\n",
    "bayesian_ridge_reg_scores = cross_validate(bayesian_ridge_reg, X_train, y_train, cv=cv,scoring=scoring)\n",
    "bayesian_ridge_reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00302005, 0.00309038, 0.00300002, 0.00236821, 0.0019865 ,\n",
       "        0.00270867, 0.00209403, 0.00292802, 0.00256872, 0.00208259]),\n",
       " 'score_time': array([0.00094533, 0.00049043, 0.        , 0.00108576, 0.00090814,\n",
       "        0.        , 0.00097752, 0.        , 0.0009923 , 0.00105834]),\n",
       " 'test_r2': array([0.5580764 , 0.55272494, 0.60845224, 0.55717268, 0.51299808,\n",
       "        0.59288975, 0.56993517, 0.56835791, 0.57566932, 0.51824858]),\n",
       " 'test_neg_mean_squared_error': array([-0.4384767 , -0.45750159, -0.39717032, -0.43064257, -0.48723717,\n",
       "        -0.42470162, -0.42992546, -0.42932051, -0.42654539, -0.45374548]),\n",
       " 'test_neg_median_absolute_error': array([-0.44939669, -0.46293344, -0.41152178, -0.45162038, -0.48035335,\n",
       "        -0.45501313, -0.4486084 , -0.46387273, -0.44601794, -0.44779009])}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent Regression\n",
    "sgd_reg = linear_model.SGDRegressor()\n",
    "sgd_reg_scores = cross_validate(sgd_reg, scale(X_train), scale(y_train), cv=cv,scoring=scoring)\n",
    "sgd_reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R Squared</th>\n",
       "      <th>Negative Mean Squared Error</th>\n",
       "      <th>Negative Mean Absolute Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.56515</td>\n",
       "      <td>-0.54949</td>\n",
       "      <td>-0.50421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.56515</td>\n",
       "      <td>-0.54949</td>\n",
       "      <td>-0.50421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression</th>\n",
       "      <td>0.30014</td>\n",
       "      <td>-0.88472</td>\n",
       "      <td>-0.66247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARS Lasso Regression</th>\n",
       "      <td>0.30014</td>\n",
       "      <td>-0.88472</td>\n",
       "      <td>-0.66247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge Regression</th>\n",
       "      <td>0.56514</td>\n",
       "      <td>-0.54949</td>\n",
       "      <td>-0.50427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stochastic Gradient Descent Regression</th>\n",
       "      <td>0.56145</td>\n",
       "      <td>-0.43753</td>\n",
       "      <td>-0.45171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        R Squared  \\\n",
       "Linear Regression                         0.56515   \n",
       "Ridge Regression                          0.56515   \n",
       "Lasso Regression                          0.30014   \n",
       "LARS Lasso Regression                     0.30014   \n",
       "Bayesian Ridge Regression                 0.56514   \n",
       "Stochastic Gradient Descent Regression    0.56145   \n",
       "\n",
       "                                        Negative Mean Squared Error  \\\n",
       "Linear Regression                                          -0.54949   \n",
       "Ridge Regression                                           -0.54949   \n",
       "Lasso Regression                                           -0.88472   \n",
       "LARS Lasso Regression                                      -0.88472   \n",
       "Bayesian Ridge Regression                                  -0.54949   \n",
       "Stochastic Gradient Descent Regression                     -0.43753   \n",
       "\n",
       "                                        Negative Mean Absolute Error  \n",
       "Linear Regression                                           -0.50421  \n",
       "Ridge Regression                                            -0.50421  \n",
       "Lasso Regression                                            -0.66247  \n",
       "LARS Lasso Regression                                       -0.66247  \n",
       "Bayesian Ridge Regression                                   -0.50427  \n",
       "Stochastic Gradient Descent Regression                      -0.45171  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table function\n",
    "def make_scores(scores):\n",
    "    temp = pd.DataFrame()\n",
    "    out = pd.DataFrame()\n",
    "    temp[\"R Squared\"] = scores[\"test_r2\"]\n",
    "    temp[\"Negative Mean Squared Error\"] = scores[\"test_neg_mean_squared_error\"]\n",
    "    temp[\"Negative Mean Absolute Error\"] = scores[\"test_neg_median_absolute_error\"]\n",
    "    r2 = (temp[\"R Squared\"].sum()/10)\n",
    "    neg_mse = (temp[\"Negative Mean Squared Error\"].sum()/10)\n",
    "    neg_mae = (temp[\"Negative Mean Absolute Error\"].sum()/10)\n",
    "    out = [r2,neg_mse,neg_mae]\n",
    "    return out\n",
    "\n",
    "# Gather together table\n",
    "\n",
    "table = pd.DataFrame()\n",
    "\n",
    "table[\"Linear Regression\"] = make_scores(lin_reg_scores)\n",
    "table[\"Ridge Regression\"] = make_scores(ridge_reg_scores)\n",
    "table[\"Lasso Regression\"] = make_scores(lasso_reg_scores)\n",
    "table[\"LARS Lasso Regression\"] = make_scores(lars_lasso_reg_scores)\n",
    "table[\"Bayesian Ridge Regression\"] = make_scores(bayesian_ridge_reg_scores)\n",
    "table[\"Stochastic Gradient Descent Regression\"] = make_scores(sgd_reg_scores)\n",
    "\n",
    "\n",
    "table = table.T\n",
    "column_names = [\"R Squared\",\"Negative Mean Squared Error\",\"Negative Mean Absolute Error\"]\n",
    "table.columns = column_names\n",
    "\n",
    "table\n",
    "#table.to_csv(\"Baseline Comparisons.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2292f7dadeec0b36dafabb7d1d8dd7b9b8b8f0665c515bec64e67bf9650aaf0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
